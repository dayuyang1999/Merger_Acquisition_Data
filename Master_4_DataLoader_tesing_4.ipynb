{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:07.539977Z",
     "start_time": "2021-10-30T21:39:07.535207Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each firm, you need to have corresponding:\n",
    "\n",
    "[arr_b, arr_c, arr_delta_time, event_data, non_event_data, estimate_length, choice_data_dict]\n",
    "\n",
    "\n",
    "in the Dataset object, at least should have such things\n",
    "- idx_to_gvkey mapping (idx max = 511)\n",
    "    - every time you call an idx, first transfer it to gvkey, and get a batch of \n",
    "    `[arr_b, arr_c, arr_delta_time, event_data, non_event_data, estimate_length, choice_data_dict]`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:07.566907Z",
     "start_time": "2021-10-30T21:39:07.562813Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_data_path = '../MA_data/data/tmp'\n",
    "data_path = '../MA_data/data'\n",
    "\n",
    "s_year = 1997\n",
    "e_year = 2020\n",
    "\n",
    "load_timeline_from_pickle = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loader helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:07.662535Z",
     "start_time": "2021-10-30T21:39:07.657769Z"
    }
   },
   "outputs": [],
   "source": [
    "def N01_normalize(df):\n",
    "    '''\n",
    "    df could be df or array\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    normalized_df=(df-df.mean())/df.std()\n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:07.673000Z",
     "start_time": "2021-10-30T21:39:07.665668Z"
    }
   },
   "outputs": [],
   "source": [
    "def minmax_normalize(df):\n",
    "    df = df.copy()\n",
    "    normalized_df=(df-df.min())/(df.max()-df.min())\n",
    "    return normalized_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:07.708272Z",
     "start_time": "2021-10-30T21:39:07.676822Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataloader_preproceser(focal_gvkey):\n",
    "    \n",
    "    def get_arr_c(focal_gvkey):\n",
    "    # part 1, get c  \n",
    "        def get_focal_df(focal_gvkey):\n",
    "            '''\n",
    "            output: will be a df contains 3 columns: DATE, AGVKEY, EVENT_TYPE, SCORE\n",
    "                DATE: datetime.dt object\n",
    "                AGVKEY: str: 4 - 6 digits\n",
    "                EVENT_TYPE: 1:self 0:peer (integer)\n",
    "                SCORE: TNIC similarity last year for event type 0, otherwise 1\n",
    "            \n",
    "            Use DA!!!! not DE\n",
    "\n",
    "            '''\n",
    "            def helper1(row):\n",
    "                if row.AGVKEY == focal_gvkey:\n",
    "                    return 1 # integer 1\n",
    "                else:\n",
    "                    return 0 # integer 0   \n",
    "            sdc_lst = []\n",
    "            for focal_year in range(s_year-1, e_year):  \n",
    "                with open(tmp_data_path+f\"/a5_top_10_peers_tnic2_{focal_year}.pickle\", 'rb') as f:\n",
    "                    top_peers = pickle.load(f)\n",
    "                try:\n",
    "                    top_peers = top_peers[focal_gvkey] # a dataframe\n",
    "         #           print(top_peers)\n",
    "                    top_peers_lst = top_peers.gvkey2.tolist()\n",
    "                    selected_sdc_tnic = sdc_tnic[ (sdc_tnic['AGVKEY'].isin(top_peers_lst + [focal_gvkey])) & (sdc_tnic.YEAR == focal_year+1) ] \n",
    "                    selected_sdc_tnic.reset_index(drop=True)\n",
    "                    if selected_sdc_tnic.shape[0] > 0:\n",
    "                        #print(selected_sdc_tnic[['DE', 'AGVKEY']] , top_peers[['gvkey2', 'score']])\n",
    "                        df = selected_sdc_tnic[['DA', 'AGVKEY', 'TGVKEY']]\n",
    "\n",
    "\n",
    "                        df['EVENT_TYPE'] = df.apply(helper1, axis=1)\n",
    "                        #print(df)\n",
    "\n",
    "                        score_df = top_peers[['gvkey2', 'score']]\n",
    "\n",
    "                        df = df.merge(score_df, left_on='AGVKEY', right_on = 'gvkey2', how = 'left')\n",
    "                        df = df[['DA','AGVKEY', 'EVENT_TYPE', 'score', 'TGVKEY']]\n",
    "        #                print(df)\n",
    "                        df = df.fillna(1)\n",
    "                        df.columns = ['UPDATE_DATE','AGVKEY','EVENT_TYPE', 'SCORE', 'TGVKEY'] # rename\n",
    "                        df = df.reset_index(drop=True)\n",
    "                        sdc_lst.append(df)\n",
    "                    #print(len(sdc_lst))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            focal_df = pd.concat(sdc_lst, axis=0)\n",
    "            focal_c = focal_df.reset_index(drop=True) \n",
    "            focal_c = focal_c.sort_values(by = ['UPDATE_DATE']) # date time is unsortable..\n",
    "            focal_c.reset_index(drop=True, inplace=True)\n",
    "            return focal_c\n",
    "\n",
    "        def convert_date(df):\n",
    "            def datetime_converter(date_time):\n",
    "                base_time = np.datetime64('1997-01-01')\n",
    "                days_diff = np.datetime64(date_time.date()) - base_time\n",
    "                return days_diff.astype(int)\n",
    "            for idx, row in df.iterrows():\n",
    "                df.loc[idx, 'UPDATE_DATE'] = datetime_converter(df.loc[idx, 'UPDATE_DATE'])\n",
    "\n",
    "            df.sort_values(by = ['UPDATE_DATE']).reset_index(drop=True, inplace=True)\n",
    "            return df\n",
    "\n",
    "        def making_time_diff(focal_c2):\n",
    "            '''\n",
    "            df = focal_c; update date is the integer form that count the date from base_date (1997 01 01)\n",
    "\n",
    "            WARNING: the No.1 event set time-diff = 0\n",
    "            '''\n",
    "            tmp_columns = focal_c2.columns.tolist()\n",
    "      \n",
    "            focal_c2['UPDATE_DATE'] = [0] + [1 if timediff==0 else timediff for timediff in focal_c2.UPDATE_DATE.diff().tolist()[1:] ]\n",
    "            focal_c2.columns = ['time_diff'] + tmp_columns[1:]\n",
    "            return focal_c2\n",
    "\n",
    "        def __main__():\n",
    "            focal_c = get_focal_df(focal_gvkey)\n",
    "            focal_c2 = convert_date(focal_c.copy())\n",
    "            focal_c3 = making_time_diff(focal_c2.copy())\n",
    "            arr_c = np.array(focal_c3[['time_diff', 'EVENT_TYPE', 'SCORE']])\n",
    "            \n",
    "            return arr_c, focal_c\n",
    "\n",
    "        arr, focal_c = __main__()\n",
    "\n",
    "        return arr, focal_c\n",
    "\n",
    "    def get_arr_b(focal_c, focal_gvkey):\n",
    "        def add_datetime(df):\n",
    "            def helper(row):\n",
    "                return np.datetime64(str(row.year+1)+'-01-01')\n",
    "            df['UPDATE_DATE'] = df.apply(helper, axis=1)\n",
    "            return df\n",
    "        def obtain_fv(focal_gvkey, focal_c, fv):\n",
    "            year_min, year_max = min([date.year for date in focal_c.UPDATE_DATE.tolist()]), max([date.year for date in focal_c.UPDATE_DATE.tolist()])\n",
    "            fv_subset = fv[(fv.year >= year_min-1) & (fv.year <= year_max-1) & (fv.gvkey == focal_gvkey)]\n",
    "            fv_subset = fv_subset[['gvkey', 'year','UPDATE_DATE', 'at', 'sale', 'ch', 'm2b', 'lev', 'roa', 'ppe',\n",
    "               'cash2asset', 'cash2sale', 'sale2asset', 'de', 'roe', 'd_sale', 'd_at']]\n",
    "            fv_subset.columns=['AGVKEY', 'year','UPDATE_DATE', 'at', 'sale', 'ch', 'm2b', 'lev', 'roa', 'ppe',\n",
    "               'cash2asset', 'cash2sale', 'sale2asset', 'de', 'roe', 'd_sale', 'd_at']\n",
    "            \n",
    "            \n",
    "            return fv_subset\n",
    "\n",
    "        def __main__():\n",
    "            with open(tmp_data_path+\"/afreq_full_fv.pickle\", \"rb\") as f:\n",
    "                fv = pickle.load(f)\n",
    "            fv = add_datetime(fv)\n",
    "            focal_b = obtain_fv(\"5047\", focal_c, fv)\n",
    "            arr_b = np.array(focal_b.iloc[:, 3:])\n",
    "            arr_b = N01_normalize(arr_b)\n",
    "            return arr_b, focal_b\n",
    "\n",
    "        arr = __main__()\n",
    "        return arr\n",
    "\n",
    "    def create_main_timeline(focal_b, focal_c):\n",
    "        '''\n",
    "        WARNING: GLOBAL and LOCAL time both start from 0!\n",
    "\n",
    "        '''\n",
    "        def helper(row):\n",
    "            if (row.EVENT_TYPE == 1) or (row.EVENT_TYPE == 0):\n",
    "                return 'past'\n",
    "            else:\n",
    "                return \"fv\"\n",
    "\n",
    "        def helper2(row):\n",
    "            if row.EVENT_TYPE == 1:\n",
    "                return \"1\"\n",
    "            elif row.EVENT_TYPE == 0:\n",
    "                return \"2\"\n",
    "            else:\n",
    "                return \"3\"\n",
    "\n",
    "        tmp = pd.concat([focal_c, focal_b]).sort_values(by=['UPDATE_DATE'])\n",
    "        tmp['EVENT_TYPE_countcreater'] = tmp.apply(helper, axis=1)\n",
    "        tmp['EVENT_TYPE_true'] = tmp.apply(helper2, axis=1)\n",
    "        tmp['LOCAL_IDX'] = tmp.groupby(['EVENT_TYPE_countcreater'])['UPDATE_DATE'].rank(ascending=True) -1 # rank start with 1\n",
    "        tmp['LOCAL_IDX'] = tmp['LOCAL_IDX'].astype(int)\n",
    "        ## with local_idx using rank, local idx is not continuous (may have gap)\n",
    "        \n",
    "        tmp_columns = tmp.columns\n",
    "        tmp.reset_index(drop=True, inplace=True)\n",
    "        tmp.reset_index(drop=False, inplace=True)\n",
    "\n",
    "        tmp.columns = ['GLOBAL_IDX']+ tmp_columns.tolist() # rename global index\n",
    "\n",
    "        tmp = tmp[['GLOBAL_IDX', 'LOCAL_IDX', 'UPDATE_DATE', 'EVENT_TYPE_true', 'TGVKEY']]\n",
    "\n",
    "        tmp.columns = ['GLOBAL_IDX', 'LOCAL_IDX', 'UPDATE_DATE', 'EVENT_TYPE', 'TGVKEY'] # rename\n",
    "\n",
    "\n",
    "\n",
    "        return tmp\n",
    "    \n",
    "    def __main__():\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            arr_c, focal_c = get_arr_c(focal_gvkey)\n",
    "        arr_b, focal_b = get_arr_b(focal_c, focal_gvkey)\n",
    "        timeline = create_main_timeline(focal_b, focal_c)\n",
    "        return arr_c, arr_b, timeline\n",
    "    \n",
    "    arr_c, arr_b, timeline = __main__()\n",
    "    return arr_c, arr_b, timeline\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:07.717766Z",
     "start_time": "2021-10-30T21:39:07.710258Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_freq_a(sdc_tnic, min_event=5):\n",
    "    A_freq = pd.DataFrame(sdc_tnic.AGVKEY.value_counts()).reset_index(drop=False)\n",
    "    A_freq = A_freq[A_freq.AGVKEY >= min_event]\n",
    "    A_freq.columns = [\"GVKEY\", \"freq\"]\n",
    "    print(f\"totally {A_freq.shape[0]} numbers of frequent Acquirers\")\n",
    "    a_freq_idx_to_gvkey_mapping = {}\n",
    "    a_freq_gvkey_to_idx_mapping = {}\n",
    "    for i, row in A_freq.iterrows():\n",
    "        a_freq_idx_to_gvkey_mapping[i] = row.GVKEY\n",
    "        a_freq_gvkey_to_idx_mapping[row.GVKEY] = i\n",
    "    a_freq_lst = A_freq.GVKEY.values.tolist()\n",
    "    return A_freq,a_freq_lst, a_freq_idx_to_gvkey_mapping, a_freq_gvkey_to_idx_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:07.724709Z",
     "start_time": "2021-10-30T21:39:07.719291Z"
    }
   },
   "outputs": [],
   "source": [
    "def same_day_only_one(sdc_tnic_raw):\n",
    "    print(\"shape before removing same-day multi events:\", sdc_tnic_raw.shape)\n",
    "    sdc_tnic_raw = sdc_tnic_raw.copy()\n",
    "    sdc_tnic_one = sdc_tnic_raw.groupby(['AGVKEY', 'DA']).first().reset_index(drop=False)\n",
    "    print(\"shape after removing same-day multi events:\", sdc_tnic_one.shape)\n",
    "    sdc_tnic_one.sort_values(by = ['DA'], axis=0, inplace=True)\n",
    "    return sdc_tnic_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:07.939404Z",
     "start_time": "2021-10-30T21:39:07.726429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before removing same-day multi events: (9661, 50)\n",
      "shape after removing same-day multi events: (9448, 50)\n"
     ]
    }
   ],
   "source": [
    "sdc_tnic = pd.read_pickle(tmp_data_path+f\"/sdc_tnic_{s_year}_{e_year}\")\n",
    "sdc_tnic = same_day_only_one(sdc_tnic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:08.005403Z",
     "start_time": "2021-10-30T21:39:07.940645Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(tmp_data_path+f\"/tnic_info_3_pairs_{s_year-1}_{e_year-1}\", 'rb') as f:\n",
    "    gvkey_lsts, key_ind_maps , ind_key_maps = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:08.038858Z",
     "start_time": "2021-10-30T21:39:08.007077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totally 496 numbers of frequent Acquirers\n"
     ]
    }
   ],
   "source": [
    "A_freq, a_freq_lst, a_freq_idx_to_gvkey_mapping, a_freq_gvkey_to_idx_mapping = create_freq_a(sdc_tnic)\n",
    "\n",
    "a_freq_info = (A_freq, a_freq_lst, a_freq_idx_to_gvkey_mapping, a_freq_gvkey_to_idx_mapping)\n",
    "\n",
    "# with open(data_path+f\"/freq_a_info_{s_year}_{e_year}.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(a_freq_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:08.042811Z",
     "start_time": "2021-10-30T21:39:08.040820Z"
    }
   },
   "outputs": [],
   "source": [
    "testing_gvkey = '121817'\n",
    "a_freq_lst = [testing_gvkey]\n",
    "testing_idx = a_freq_gvkey_to_idx_mapping[testing_gvkey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:10.986623Z",
     "start_time": "2021-10-30T21:39:08.044246Z"
    }
   },
   "outputs": [],
   "source": [
    "arr_cs = []\n",
    "arr_bs = []\n",
    "timelines = []\n",
    "\n",
    "arr_c, arr_b, timeline = dataloader_preproceser(testing_gvkey)\n",
    "\n",
    "arr_cs.append(arr_c)\n",
    "arr_bs.append(arr_b)\n",
    "timelines.append(timeline)\n",
    "\n",
    "#idx_to_gvkey[testing_idx] = testing_gvkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:11.070525Z",
     "start_time": "2021-10-30T21:39:10.987880Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_path+\"/fv_raw_full_1996_2019.pickle\", 'rb') as f:\n",
    "    fv_full = pickle.load(f)\n",
    "fv_full = pd.concat([fv_full.iloc[:,:2], N01_normalize(fv_full.iloc[:, 2:])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:11.083534Z",
     "start_time": "2021-10-30T21:39:11.071846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gvkey         0\n",
       "year          0\n",
       "at            0\n",
       "sale          0\n",
       "ch            0\n",
       "rdip          0\n",
       "m2b           0\n",
       "lev           0\n",
       "roa           0\n",
       "ppe           0\n",
       "cash2asset    0\n",
       "cash2sale     0\n",
       "sale2asset    0\n",
       "cr            0\n",
       "gsi           0\n",
       "de            0\n",
       "roe           0\n",
       "d_sale        0\n",
       "d_at          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv_full.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:11.092849Z",
     "start_time": "2021-10-30T21:39:11.084684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLOBAL_IDX</th>\n",
       "      <th>LOCAL_IDX</th>\n",
       "      <th>UPDATE_DATE</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>TGVKEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-03-06</td>\n",
       "      <td>2</td>\n",
       "      <td>3105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-03-06</td>\n",
       "      <td>2</td>\n",
       "      <td>3105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-03-06</td>\n",
       "      <td>1</td>\n",
       "      <td>3105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-03-13</td>\n",
       "      <td>2</td>\n",
       "      <td>10580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>41</td>\n",
       "      <td>2018-12-03</td>\n",
       "      <td>2</td>\n",
       "      <td>10726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>42</td>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>2</td>\n",
       "      <td>112030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>20</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>43</td>\n",
       "      <td>2020-12-16</td>\n",
       "      <td>2</td>\n",
       "      <td>19578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    GLOBAL_IDX  LOCAL_IDX UPDATE_DATE EVENT_TYPE  TGVKEY\n",
       "0            0          0  2000-01-01          3     NaN\n",
       "1            1          1  2000-03-06          2    3105\n",
       "2            2          1  2000-03-06          2    3105\n",
       "3            3          1  2000-03-06          1    3105\n",
       "4            4          3  2000-03-13          2   10580\n",
       "..         ...        ...         ...        ...     ...\n",
       "60          60         41  2018-12-03          2   10726\n",
       "61          61         19  2019-01-01          3     NaN\n",
       "62          62         42  2019-02-13          2  112030\n",
       "63          63         20  2020-01-01          3     NaN\n",
       "64          64         43  2020-12-16          2   19578\n",
       "\n",
       "[65 rows x 5 columns]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timelines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:11.099049Z",
     "start_time": "2021-10-30T21:39:11.093660Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_arr_b_idx(df):\n",
    "    '''\n",
    "    df is the a timeline table of a single firm (the 3rd output of preprocess function)\n",
    "    output is a list\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    sample_df = df.copy()\n",
    "    sub1 = sample_df[(sample_df.EVENT_TYPE == '1')& (sample_df.LOCAL_IDX >=2)] # happened at 3rd time \n",
    "\n",
    "    global_idxs = sub1.GLOBAL_IDX.values # array\n",
    "\n",
    "    arr_b_idxs = []\n",
    "    for global_idx in global_idxs:\n",
    "        sub2 = sample_df[(sample_df.EVENT_TYPE == '3') & (sample_df.GLOBAL_IDX < global_idx)]\n",
    "        arr_b_idx = sub2.iloc[-1, 1] # get local index of arr_b\n",
    "        arr_b_idxs.append(arr_b_idx)\n",
    "\n",
    "    return arr_b_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:11.108097Z",
     "start_time": "2021-10-30T21:39:11.100117Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_c_t_idx(df):\n",
    "    sample_df = df.copy()\n",
    "    sub1 = sample_df[(sample_df.EVENT_TYPE == '1')& (sample_df.LOCAL_IDX >=2)] \n",
    "    local_idxs = sub1.LOCAL_IDX.values # array\n",
    "    \n",
    "    arr_c_idxs = []\n",
    "    arr_t_idxs = []\n",
    "    for local_idx in local_idxs:\n",
    "        sub2 = sample_df[(sample_df.EVENT_TYPE.isin(['1','2'])) & (sample_df.LOCAL_IDX < local_idx)]\n",
    "#        print(sub2)\n",
    "        arr_c_idx = sub2.iloc[-1, 1] -1 # get local index\n",
    "        arr_t_idx = sub2.iloc[-1, 1]\n",
    "        arr_c_idxs.append(arr_c_idx)\n",
    "        arr_t_idxs.append(arr_t_idx)\n",
    "    return arr_c_idxs, arr_t_idxs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:11.114684Z",
     "start_time": "2021-10-30T21:39:11.109319Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_date(df):\n",
    "    df = df.copy()\n",
    "    def datetime_converter(date_time):\n",
    "        base_time = np.datetime64('1997-01-01')\n",
    "        days_diff = np.datetime64(date_time.date()) - base_time\n",
    "        return days_diff.astype(int)\n",
    "    for idx, row in df.iterrows():\n",
    "        df.loc[idx, 'UPDATE_DATE_int'] = datetime_converter(df.loc[idx, 'UPDATE_DATE'])\n",
    "\n",
    "    #df.sort_values(by = ['UPDATE_DATE']).reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:11.121407Z",
     "start_time": "2021-10-30T21:39:11.115950Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_negative_time_point(df, base_n_sample=10):\n",
    "    '''\n",
    "    df is timeline + 'UPDATE_DATE_int'\n",
    "    \n",
    "    number of negative samples is corresponding to the number of positive samples (follow the idea of negative smapling in skip-gram)\n",
    "        each word, approx 10 negative samples.\n",
    "    \n",
    "    '''\n",
    "    df = df.copy()\n",
    "    max_time = df.UPDATE_DATE_int.values[-1]\n",
    "    sub_df = df[df.EVENT_TYPE.isin(['1', '2']) & (df.LOCAL_IDX >=2)]\n",
    "    min_time = sub_df.UPDATE_DATE_int.values[0]\n",
    "    n_event = df[(df.EVENT_TYPE == '1') & (df.LOCAL_IDX >=2)].shape[0]\n",
    "    if n_event == 0:\n",
    "        n_event = 1\n",
    "    n_samples = base_n_sample * n_event\n",
    "    samples = np.random.uniform(low=min_time, high=max_time, size=n_samples)\n",
    "    return samples, max_time - min_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:11.130996Z",
     "start_time": "2021-10-30T21:39:11.122933Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_arr_b_idx_neg(time_samples, df):\n",
    "    '''\n",
    "    df is timeline + 'UPDATE_DATE_int'\n",
    "    \n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df_b = df[df.EVENT_TYPE == '3']\n",
    "    arr_b_idxs = []\n",
    "    for time in time_samples:\n",
    "        df_b_sub = df_b[df_b.UPDATE_DATE_int<time]\n",
    "        arr_b_idxs.append(df_b_sub.iloc[-1, 1])\n",
    "    \n",
    "    return arr_b_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:11.138167Z",
     "start_time": "2021-10-30T21:39:11.132830Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_arr_c_t_idx_neg(time_samples, df):\n",
    "    '''\n",
    "    df is timeline + 'UPDATE_DATE_int'\n",
    "    total columns are: [GLOBAL_IDX  LOCAL_IDX UPDATE_DATE EVENT_TYPE  UPDATE_DATE_int]\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df_c = df[df.EVENT_TYPE.isin(['1', '2']) & (df.LOCAL_IDX >=2)]\n",
    "\n",
    "    arr_c_idxs_neg = []\n",
    "    arr_t_neg = []\n",
    "    for time in time_samples:\n",
    "        df_before = df_c[df_c.UPDATE_DATE_int < time]\n",
    "        #print(time)\n",
    "        \n",
    "        arr_c_idx_neg = df_before.iloc[-1, 1] # here do not -1!\n",
    "        previous_time = df_before.iloc[-1, 5]\n",
    "        \n",
    "        arr_c_idxs_neg.append(arr_c_idx_neg)\n",
    "        #print(time, previous_time)\n",
    "        arr_t_neg.append(time - previous_time)\n",
    "    \n",
    "    return arr_c_idxs_neg, np.array(arr_t_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:11.149282Z",
     "start_time": "2021-10-30T21:39:11.140289Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_arr_b_c_idx_i(df, s_year, e_year):\n",
    "    '''\n",
    "    df is timeline + 'UPDATE_DATE_int'\n",
    "    total columns are: [GLOBAL_IDX  LOCAL_IDX UPDATE_DATE EVENT_TYPE  UPDATE_DATE_int]\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    # create a year variable\n",
    "    def helper(row):\n",
    "        return row.UPDATE_DATE.year\n",
    "    df['year'] = df.apply(helper, axis=1)\n",
    "    \n",
    "    # qualified self event\n",
    "    sub = df[(df.EVENT_TYPE == '1') & (df.LOCAL_IDX >= 2)]\n",
    "    \n",
    "    yearly = {}\n",
    "    for year in range(s_year, e_year+1):\n",
    "        b_idxs = []\n",
    "        c_idxs = []\n",
    "        sub2 = sub[sub.year == year] # self event at particular year\n",
    "        for _, row in sub2.iterrows():\n",
    "            time = row.UPDATE_DATE_int # float\n",
    "            # back to global df\n",
    "            df_b_before = df[(df.UPDATE_DATE_int < time)&(df.EVENT_TYPE == '3')]\n",
    "            df_c_before = df[(df.UPDATE_DATE_int < time)&(df.EVENT_TYPE.isin(['1','2']))]\n",
    "            idx_b = df_b_before.iloc[-1, 1]\n",
    "            idx_c = df_c_before.iloc[-1, 1] -1\n",
    "            b_idxs.append(idx_b)\n",
    "            c_idxs.append(idx_c)\n",
    "            \n",
    "        yearly[year] = (b_idxs, c_idxs)\n",
    "    \n",
    "    return yearly\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:11.159029Z",
     "start_time": "2021-10-30T21:39:11.151170Z"
    }
   },
   "outputs": [],
   "source": [
    "def true_tar_idxs_i(timeline, dict_idx):\n",
    "    '''\n",
    "    year loop by self-event year\n",
    "        TNIC related data use year-1\n",
    "    \n",
    "    '''\n",
    "\n",
    "        \n",
    "    # add year to timeline data\n",
    "    df = timeline.copy()\n",
    "    # create a year variable\n",
    "    def helper(row):\n",
    "        return row.UPDATE_DATE.year\n",
    "    df['year'] = df.apply(helper, axis=1)\n",
    "    \n",
    "    # qualified self event\n",
    "    sub = df[(df.EVENT_TYPE == '1') & (df.LOCAL_IDX >= 2)]\n",
    "    \n",
    "    yearly = {}\n",
    "    # loop over self-merge year\n",
    "    for year in range(s_year, e_year+1):\n",
    "        '''\n",
    "        N_i_1 = num of candidate target\n",
    "        N_i_2 = num of self event\n",
    "        '''\n",
    "        N_i_1 = len(gvkey_lsts[year-1]) # all target candidate in TNIC net\n",
    "        b_idxs, c_idxs = dict_idx[year] # the output of ...\n",
    "        N_i_2 = len(b_idxs)\n",
    "        timeline_i = sub[sub.year == year] # only ith year\n",
    "        targets_lst = timeline_i.TGVKEY.values.tolist() # length = N_i_2\n",
    "        assert len(targets_lst) == N_i_2, \"length dismatch with larget lists and N_i_2\"\n",
    "        idx_lst = [key_ind_maps[year-1][tgvkey] for tgvkey in targets_lst]\n",
    "        #one_hot_i = (np.arange(_ == a[...,None]-1).astype(int)\n",
    "        a = np.array(idx_lst)\n",
    "        one_hot_i = (np.arange(N_i_1) == a[...,None]).astype(int)\n",
    "        yearly[year] = one_hot_i\n",
    "    return yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:11.169048Z",
     "start_time": "2021-10-30T21:39:11.160737Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_node_features(fv_full, gvkey_lsts, key_ind_maps , ind_key_maps, s_year=1997, e_year=2020):\n",
    "    '''\n",
    "    fv_full: raw\n",
    "    gvkey_lsts, key_ind_maps , ind_key_maps: raw\n",
    "    \n",
    "    WARNING: the output yearly's year is self-event's year!!! \n",
    "    '''\n",
    "    # loop self-merge year\n",
    "    yearly = {}\n",
    "    for year in range(s_year, e_year+1): \n",
    "        df_gvkeys = pd.DataFrame({'gvkeys': gvkey_lsts[year-1]})\n",
    "        fv_candidate = fv_full[fv_full.gvkey.isin(gvkey_lsts[year-1]) & (fv_full.year == year-1)]\n",
    "        fv_i = df_gvkeys.merge(fv_candidate, left_on='gvkeys', right_on = 'gvkey', how = \"left\")\n",
    "        fv_i.reset_index(drop=True, inplace=True)\n",
    "        #print(fv_i[:5])\n",
    "        arr = fv_i.iloc[:, 3:].to_numpy()\n",
    "        yearly[year] = arr\n",
    "        assert len(gvkey_lsts[year-1]) == arr.shape[0], \"list and arr shape dismatch\"\n",
    "    \n",
    "    return yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:11.179152Z",
     "start_time": "2021-10-30T21:39:11.171079Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_net_structure(tmp_data_path, gvkey_lsts, key_ind_maps , ind_key_maps, s_year=1997, e_year=2020):\n",
    "    \n",
    "    yearly = {}    \n",
    "    # loop over self-event year! not TNIC !\n",
    "    for year in range(s_year, e_year+1):     \n",
    "        with open(tmp_data_path+f'/a5_top_10_peers_tnic2_{year-1}.pickle', 'rb') as f:\n",
    "            tnic = pickle.load(f)   \n",
    "            df_all_lst = []\n",
    "            for _,value in tnic.items():\n",
    "                df_all_lst.append(value)\n",
    "            df_all = pd.concat(df_all_lst)\n",
    "            df_net = df_all[['gvkey1', 'gvkey2']]\n",
    "            lst1 = df_net.gvkey1.values.tolist()\n",
    "            lst2 = df_net.gvkey2.values.tolist()\n",
    "            idx1 = [key_ind_maps[year-1][gvkey1] for gvkey1 in lst1]\n",
    "            idx2 = [key_ind_maps[year-1][gvkey2] for gvkey2 in lst2]\n",
    "            arr = np.array([idx1, idx2])\n",
    "            assert arr.shape[0] == 2, \"the dim of output is wrong\"\n",
    "        yearly[year] = arr\n",
    "    return yearly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create A freq\n",
    "\n",
    "- if change this section, `[arr_cs, arr_bs, timelines]` should be rebuild instead of load from picklle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create everything/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:11.188747Z",
     "start_time": "2021-10-30T21:39:11.180933Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    ma_dataset = []\n",
    "    for i, gvkey in enumerate(tqdm(a_freq_lst)):\n",
    "        '''\n",
    "        the rest variables are for a specific freq acquirer\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "    \n",
    "        ######### get arr_c and arr_delta_time\n",
    "        arr_c = arr_cs[i]\n",
    "        arr_c = arr_c[1:] # remove the first row!\n",
    "        arr_delta_time = arr_c[:, 0]\n",
    "        # get arr_b\n",
    "        arr_b = arr_bs[i]\n",
    "        \n",
    "        ######## Event data\n",
    "        timeline = convert_date(timelines[i]) # add UPDATE_DATE_int column\n",
    "        #print(timeline.columns)\n",
    "        # arr_b_idx\n",
    "        arr_b_idx = get_arr_b_idx(timeline)\n",
    "        arr_b_idx = np.array(arr_b_idx)\n",
    "        # arr_c_idx and arr_delta_time\n",
    "        arr_c_idx, arr_t_idx = get_c_t_idx(timeline)\n",
    "        arr_c_idx = np.array(arr_c_idx) # event data arr_c_idx\n",
    "        arr_t_idx = np.array(arr_t_idx) \n",
    "\n",
    "        arr_delta_time = arr_delta_time[list(arr_t_idx)]\n",
    "        event_data = (arr_b_idx, arr_c_idx, arr_delta_time)\n",
    "        \n",
    "        ######## Non- Event data\n",
    "        # estimate_time_length\n",
    "        samples, estimate_time_length = sample_negative_time_point(timeline)\n",
    "        #  arr_b_idx\n",
    "        non_arr_b_idx =  get_arr_b_idx_neg(samples, timeline)\n",
    "        non_arr_b_idx = np.array(non_arr_b_idx)\n",
    "\n",
    "        non_arr_c_idx, non_arr_delta_time = get_arr_c_t_idx_neg(samples, timeline)\n",
    "        non_arr_c_idx = np.array(non_arr_c_idx)\n",
    "        \n",
    "        non_event_data = (non_arr_b_idx, non_arr_c_idx, non_arr_delta_time)\n",
    "        ######## Choice data dict\n",
    "        dict_idx = get_arr_b_c_idx_i(timeline, s_year, e_year)\n",
    "        true_tar_idxs = true_tar_idxs_i(timeline, dict_idx)\n",
    "        node_feature = get_node_features(fv_full, gvkey_lsts, key_ind_maps , ind_key_maps, s_year, e_year)\n",
    "        net_structure = get_net_structure(tmp_data_path, gvkey_lsts, key_ind_maps , ind_key_maps, s_year, e_year)\n",
    "        choice_data_dict = (dict_idx, true_tar_idxs, node_feature, net_structure)\n",
    "        ma_dataset.append((arr_b, arr_c, arr_delta_time, event_data, non_event_data, estimate_time_length, choice_data_dict))\n",
    "  \n",
    "    return ma_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:15.987248Z",
     "start_time": "2021-10-30T21:39:11.190269Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.78s/it]\n"
     ]
    }
   ],
   "source": [
    "ma_dataset = create_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:16.018985Z",
     "start_time": "2021-10-30T21:39:15.988599Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(data_path+\"/ma_dataset_test.pickle\", 'wb') as f:\n",
    "    pickle.dump(ma_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:16.025488Z",
     "start_time": "2021-10-30T21:39:16.021859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ma_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:16.036247Z",
     "start_time": "2021-10-30T21:39:16.027244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.48449981,  0.42709089, -0.08891779, -0.34752582, -0.3475372 ,\n",
       "        -0.3475405 , -0.34753997, -0.34754031, -0.34753893, -0.34753877,\n",
       "        -0.34750754, -0.34753892, -0.34753991, -0.34753971],\n",
       "       [ 2.70679961,  0.54743863, -0.29026385, -0.34752702, -0.34753746,\n",
       "        -0.34754048, -0.34754004, -0.34754055, -0.34754023, -0.34753863,\n",
       "        -0.34751282, -0.34753892, -0.3475396 , -0.34754013],\n",
       "       [ 3.11229442,  0.53086015, -0.28406439, -0.34752898, -0.34753739,\n",
       "        -0.34754048, -0.34754009, -0.34754055, -0.34754018, -0.34753891,\n",
       "        -0.34751099, -0.34753888, -0.34754081, -0.34753975],\n",
       "       [ 3.67297833,  0.56584829, -0.28526654, -0.34753167, -0.34753729,\n",
       "        -0.3475405 , -0.34754011, -0.34754057, -0.34754021, -0.34753909,\n",
       "        -0.34751003, -0.34753902, -0.3475404 , -0.34753955],\n",
       "       [ 4.17787411,  0.58611709, -0.25902893, -0.34753132, -0.34753739,\n",
       "        -0.34754051, -0.34754011, -0.34754054, -0.34754002, -0.34753924,\n",
       "        -0.34751377, -0.34753931, -0.34754053, -0.3475398 ],\n",
       "       [ 3.14091636,  0.4621862 , -0.08891779, -0.34753024, -0.347537  ,\n",
       "        -0.34754052, -0.34753994, -0.34754031, -0.34753893, -0.34753887,\n",
       "        -0.34751171, -0.34753927, -0.34754067, -0.34754003],\n",
       "       [ 3.14091636,  0.4621862 , -0.08891779, -0.34753024, -0.347537  ,\n",
       "        -0.34754052, -0.34753994, -0.34754031, -0.34753893, -0.34753887,\n",
       "        -0.34751171, -0.34753927, -0.34754067, -0.34754003],\n",
       "       [ 3.14091636,  0.4621862 , -0.08891779, -0.34753024, -0.347537  ,\n",
       "        -0.34754052, -0.34753994, -0.34754031, -0.34753893, -0.34753887,\n",
       "        -0.34751171, -0.34753927, -0.34754067, -0.34754003],\n",
       "       [ 5.21126137,  0.83866633, -0.2374811 , -0.34753156, -0.34753616,\n",
       "        -0.34754048, -0.34754   , -0.34754054, -0.34754003, -0.34753919,\n",
       "        -0.34750959, -0.34753932, -0.34754067, -0.34754003],\n",
       "       [ 3.14091636,  0.4621862 , -0.08891779, -0.34753024, -0.347537  ,\n",
       "        -0.34754052, -0.34753994, -0.34754031, -0.34753893, -0.34753887,\n",
       "        -0.34751171, -0.34753927, -0.34754067, -0.34754003],\n",
       "       [ 5.11677382,  0.74122233,  0.15750188, -0.34753332, -0.34753612,\n",
       "        -0.34754058, -0.34754006, -0.34754004, -0.34753744, -0.34753929,\n",
       "        -0.34751028, -0.34754001, -0.34754067, -0.34754003],\n",
       "       [ 4.90288906,  0.6942756 ,  0.20431582, -0.34753302, -0.34753623,\n",
       "        -0.34754056, -0.34754007, -0.34753995, -0.34753698, -0.34753929,\n",
       "        -0.34751255, -0.34753994, -0.34754098, -0.34754096],\n",
       "       [ 3.14091636,  0.4621862 , -0.08891779, -0.34753024, -0.347537  ,\n",
       "        -0.34754052, -0.34753994, -0.34754031, -0.34753893, -0.34753887,\n",
       "        -0.34751171, -0.34753927, -0.34754067, -0.34754003],\n",
       "       [ 3.14091636,  0.4621862 , -0.08891779, -0.34753024, -0.347537  ,\n",
       "        -0.34754052, -0.34753994, -0.34754031, -0.34753893, -0.34753887,\n",
       "        -0.34751171, -0.34753927, -0.34754067, -0.34754003],\n",
       "       [ 3.14091636,  0.4621862 , -0.08891779, -0.34753024, -0.347537  ,\n",
       "        -0.34754052, -0.34753994, -0.34754031, -0.34753893, -0.34753887,\n",
       "        -0.34751171, -0.34753927, -0.34754067, -0.34754003],\n",
       "       [ 4.1839268 ,  0.67397884,  0.28294478, -0.34753233, -0.34753675,\n",
       "        -0.34754052, -0.34753997, -0.34753971, -0.34753637, -0.34753911,\n",
       "        -0.34752078, -0.34753984, -0.34754067, -0.34754003],\n",
       "       [ 3.14091636,  0.31290067, -0.08891779, -0.34753024, -0.347537  ,\n",
       "        -0.34754052, -0.34753994, -0.34754031, -0.34753893, -0.34753887,\n",
       "        -0.34751171, -0.34753927, -0.34754315, -0.34754003],\n",
       "       [ 3.14091636,  0.37442696, -0.08891779, -0.34753024, -0.347537  ,\n",
       "        -0.34754052, -0.34753994, -0.34754031, -0.34753893, -0.34753887,\n",
       "        -0.34751171, -0.34753927, -0.34754003, -0.34754003],\n",
       "       [ 3.14091636,  0.34634419, -0.08891779, -0.34753024, -0.347537  ,\n",
       "        -0.34754052, -0.34753994, -0.34754031, -0.34753893, -0.34753887,\n",
       "        -0.34751171, -0.34753927, -0.34754095, -0.34754003],\n",
       "       [ 3.14091636,  0.33049958, -0.08891779, -0.34753024, -0.347537  ,\n",
       "        -0.34754052, -0.34753994, -0.34754031, -0.34753893, -0.34753887,\n",
       "        -0.34751171, -0.34753927, -0.34754084, -0.34754003],\n",
       "       [ 1.50584531,  0.31793292, -0.08891779, -0.34753024, -0.347537  ,\n",
       "        -0.34754067, -0.34753947, -0.34754031, -0.34753893, -0.34753817,\n",
       "        -0.34751171, -0.34753927, -0.34754081, -0.34754003]])"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_dataset[0][0]  # arr_b (L1, 14)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:16.043440Z",
     "start_time": "2021-10-30T21:39:16.037782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 3)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_dataset[0][1].shape # arr_c (L2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:16.051021Z",
     "start_time": "2021-10-30T21:39:16.045330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_dataset[0][2].shape # arr_delta_time (L3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:16.059223Z",
     "start_time": "2021-10-30T21:39:16.052597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  2, 12])"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_dataset[0][3][0] # arr_b_idx , len = L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:16.067191Z",
     "start_time": "2021-10-30T21:39:16.061276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ma_dataset[0][3][1])  # arr_c_idx:length = L3\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:16.075190Z",
     "start_time": "2021-10-30T21:39:16.069489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ma_dataset[0][3][2])  # arr, (L3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:16.083182Z",
     "start_time": "2021-10-30T21:39:16.077615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ma_dataset[0][4][0]) # lst L_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:16.091515Z",
     "start_time": "2021-10-30T21:39:16.085560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ma_dataset[0][4][1]) # lst L_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:16.099337Z",
     "start_time": "2021-10-30T21:39:16.093792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ma_dataset[0][4][2]) # arr L_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:16.107374Z",
     "start_time": "2021-10-30T21:39:16.101395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7583.0"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_dataset[0][5] # scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:16.115130Z",
     "start_time": "2021-10-30T21:39:16.109518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 2], [6, 8])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_dataset[0][6][0][2002]  # dict_idx, arr_b_idx_i: lst, N_i_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:16.123341Z",
     "start_time": "2021-10-30T21:39:16.117306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_dataset[0][6][1][2002] # torch tensor, one-hot, size = (N_i_2, N_i_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:16.131693Z",
     "start_time": "2021-10-30T21:39:16.125743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6155, 17)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_dataset[0][6][2][2002].shape # node features array: [N_i_1, in_channels_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T21:39:16.139770Z",
     "start_time": "2021-10-30T21:39:16.133946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 7788)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_dataset[0][6][3][2002].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T21:32:32.590022Z",
     "start_time": "2021-11-02T21:32:32.561996Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T21:32:55.654230Z",
     "start_time": "2021-11-02T21:32:55.620830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.cpu_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d99b08e1309bbda1a7a60a7fe146f82e64d62b20f5527f533414b8454a1fbeeb"
  },
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
