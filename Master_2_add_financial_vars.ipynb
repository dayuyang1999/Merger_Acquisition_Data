{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T22:12:49.859786Z",
     "start_time": "2021-09-14T22:12:48.219942Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wrds\n",
    "import pickle\n",
    "from scipy.stats.mstats import winsorize\n",
    "from os.path import join as pjoin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T22:12:59.942501Z",
     "start_time": "2021-09-14T22:12:59.939519Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_data_path = './data/tmp'\n",
    "\n",
    "\n",
    "s_year = 1997\n",
    "e_year = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-12T20:19:38.034121Z",
     "start_time": "2021-09-12T20:19:31.454073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your WRDS username [dalab5]:dayuyang1999\n",
      "Enter your password:········\n",
      "WRDS recommends setting up a .pgpass file.\n",
      "Create .pgpass file now [y/n]?: y\n",
      "Created .pgpass file successfully.\n",
      "Loading library list...\n",
      "Done\n",
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "db = wrds.Connection()\n",
    "db = wrds.Connection(wrds_username='dayuyang1999')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add financial variables\n",
    "\n",
    "## get raw data\n",
    "\n",
    "According to Appendix A of Bernard et al. (2020), we need the following `COMPUSTAT` variables to compute financial ratios.\n",
    "\n",
    "| compustat code | definition                                  |\n",
    "|----------------|---------------------------------------------|\n",
    "| at             | total asset                                 |\n",
    "| ceq            | Common/Ordinary Equity - Total              |\n",
    "| csho           | Number of Common Shares Outstanding         |\n",
    "| prcc_f         | Price Close - Annual - Fiscal               |\n",
    "| txdb           | Deferred Taxes (Balance Sheet)              |\n",
    "| dlc            | Debt in Current Liabilities - Total         |\n",
    "| dltt           | Long-Term Debt - Total                      |\n",
    "| ib             | Income Before Extraordinary Items           |\n",
    "| sale           | Net Sales                                   |\n",
    "| ch             | Cash                                        |\n",
    "| ppent          | Property, Plant and Equipment - Total (Net) |\n",
    "| re             | Retained Earnings                           |\n",
    "| act            | Current Assets - Total                      |\n",
    "| lct            | Current Liabilities - Total                 |\n",
    "\n",
    "\n",
    "Bernard, Darren, Terrence Blackburne, and Jacob Thornock. 2020. “Information Flows among Rivals and Corporate Investment.” Journal of Financial Economics 136 (3): 760–79."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-12T20:19:41.021560Z",
     "start_time": "2021-09-12T20:19:41.017798Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_firm_annual_data(data_name, s_year, e_year):\n",
    "    # Among the selected variables, for those money denominated variables, the unit is million.\n",
    "    pd_afr = db.raw_sql(sql=f'''\n",
    "      select gvkey, datadate, at, ceq, csho, prcc_f, txdb, dlc, dltt, ib, sale, ch, ppent, re, act, lct\n",
    "      from comp.funda\n",
    "      where extract(year from datadate) >= {s_year} AND extract(year from datadate) <= {e_year}\n",
    "    ''', date_cols=['datadate'])\n",
    "\n",
    "    pd_afr.gvkey = pd_afr.gvkey.astype(np.int64)\n",
    "    pd_afr.to_pickle(f\"./{tmp_data_path}/{data_name}.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-12T20:19:52.028634Z",
     "start_time": "2021-09-12T20:19:41.022844Z"
    }
   },
   "outputs": [],
   "source": [
    "get_firm_annual_data('ma_fr_raw', s_year, e_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-12T20:19:52.035359Z",
     "start_time": "2021-09-12T20:19:52.031360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(477511, 17)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_afr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-12T20:19:52.042952Z",
     "start_time": "2021-09-12T20:19:52.037483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gvkey', 'datadate', 'at', 'ceq', 'csho', 'prcc_f', 'txdb', 'dlc',\n",
       "       'dltt', 'ib', 'sale', 'ch', 'ppent', 're', 'act', 'lct', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_afr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-12T14:07:15.035179Z",
     "start_time": "2021-09-12T14:07:15.021943Z"
    }
   },
   "source": [
    "## create variables\n",
    "\n",
    "Based on the above raw input variables, we construct the following financial ratios.\n",
    "\n",
    "| variable               | formula                          | definition                                                          |\n",
    "|------------------------|----------------------------------|---------------------------------------------------------------------|\n",
    "|                        |        Bernard et al. (2020) Appendix A     |                                                                     |\n",
    "| size_i                 | at                               | Firm i’s total assets                                               |\n",
    "| market-to-book ratio_i | (at+prcc_f*csho-ceq-txdb)/at     | Market-to-book assets ratio of firm i                               |\n",
    "| leverage_i             | (dlc+dltt)/at                    | Book leverage of firm i                                             |\n",
    "| roa_i                  | ib/at                            | Return-on-assets of firm i                                          |\n",
    "| sales growth_i         | (sale_{t}-sale_{t-1})/sale_{t-1} | Sales growth of firm i                                              |\n",
    "| ppe_i                  | ppent/at                         | Firm i’s net plant, property, and equipment, scaled by total assets |\n",
    "|                        |  Yang et al (2014)  Table 2     |                                                                     |\n",
    "| sale_i                 | sale                             | Firm i’s net sales                                                  |\n",
    "| cash-to-asset ratio_i  | ch/at                            | Cash flow to total assets ratio of firm i                           |\n",
    "| cash-to-sales ratio_i  | ch/sale                          | Cash flow to sales ratio of firm i                                  |\n",
    "| sales-to-asset ratio_i | sale/at                          | Net sales/total assets                                              |\n",
    "| current ratio_i        | act/lct                          | Current assets of firm i scaled by its current liabilities          |\n",
    "| asset growth_i         | (at_{t}-at_{t-1})/at_{t-1}       | Total asset growth of firm i                                        |\n",
    "\n",
    "\n",
    "Bernard, Darren, Terrence Blackburne, and Jacob Thornock. 2020. “Information Flows among Rivals and Corporate Investment.” Journal of Financial Economics 136 (3): 760–79.\n",
    "\n",
    "Yang, Chin-Sheng, Chih-Ping Wei, and Yu-Hsun Chiang. 2014. “Exploiting Technological Indicators for Effective Technology Merger and Acquisition (M&A) Predictions.” Decision Sciences 45 (1): 147–74."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-12T20:19:52.048408Z",
     "start_time": "2021-09-12T20:19:52.045017Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper func\n",
    "def get_lags(sub_pd):\n",
    "    sub_pd = sub_pd[['gvkey', 'year', 'sale', 'at']]\n",
    "    sub_pd[['lag_year', 'lag_sale', 'lag_at']] = sub_pd[['year', 'sale', 'at']].shift(1)\n",
    "    return sub_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-12T20:19:52.069315Z",
     "start_time": "2021-09-12T20:19:52.050475Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_var(df):\n",
    "    '''\n",
    "    df:  financial var, must contain:\n",
    "        - gvkey\n",
    "        - datadate\n",
    "        - and other variables you interested in\n",
    "    \n",
    "    '''\n",
    "    pd_afr = df\n",
    "    #### pre\n",
    "    # create year and sort\n",
    "    pd_afr['year'] = pd_afr.datadate.dt.year \n",
    "    pd_afr = pd_afr.sort_values(['gvkey', 'year', 'datadate'], ascending=True)\n",
    "    \n",
    "    # check, each firm-year observation should only be observed once\n",
    "    pd_afr = pd_afr.groupby(['gvkey', 'year'], sort=False).tail(1)\n",
    "    \n",
    "    #### create \n",
    "    # keep at and sale\n",
    "    ratio_pd = pd_afr[['gvkey', 'year', 'at', 'sale']].copy()\n",
    "    \n",
    "    # market to book ratio\n",
    "    ratio_pd['m2b'] = (pd_afr['at']+pd_afr['prcc_f']*pd_afr['csho']-pd_afr['ceq']-pd_afr['txdb'])/(pd_afr['at'])\n",
    "    \n",
    "    # leverage\n",
    "    ratio_pd['lev'] = (pd_afr['dlc']+pd_afr['dltt'])/(pd_afr['at'])\n",
    "    \n",
    "    # return on asset\n",
    "    ratio_pd['roa'] = pd_afr['ib']/(pd_afr['at'])\n",
    "\n",
    "    # various ratios\n",
    "    ratio_pd['ppe'] = pd_afr['ppent']/(pd_afr['at'])\n",
    "    ratio_pd['cash2asset'] = pd_afr['ch']/(pd_afr['at']) \n",
    "    ratio_pd['cash2sale'] = pd_afr['ch']/(pd_afr['sale'])\n",
    "    ratio_pd['sale2asset'] = pd_afr['sale']/(pd_afr['at'])\n",
    "    \n",
    "    # current ratio\n",
    "    ratio_pd['cr'] = pd_afr['act']/(pd_afr['lct']) \n",
    "    \n",
    "    # sale growth\n",
    "    growth_pd = pd_afr[['gvkey', 'year', 'sale', 'at']].copy()\n",
    "    growth_pd[['lag_year', 'lag_sale', 'lag_at']] = growth_pd.groupby('gvkey', sort=False)[['year', 'sale', 'at']].shift(1)\n",
    "    growth_pd['d_sale'] = (growth_pd['sale'] - growth_pd['lag_sale'])/growth_pd['lag_sale']\n",
    "    growth_pd['d_at'] = (growth_pd['at'] - growth_pd['lag_at'])/growth_pd['lag_at']\n",
    "    \n",
    "    #print('check df structure ok: ', growth_pd.head(5))\n",
    "    \n",
    "    ratio_pd = ratio_pd.merge(growth_pd[['gvkey', 'year', 'd_sale', 'd_at']])\n",
    "    \n",
    "    \n",
    "    print('check df created ok: \\n', ratio_pd.head(1))\n",
    "    \n",
    "    print('\\n variable lists of ratio pd: ', ratio_pd.columns)\n",
    "    \n",
    "    return ratio_pd\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T01:43:39.121479Z",
     "start_time": "2021-09-14T01:43:39.031353Z"
    }
   },
   "outputs": [],
   "source": [
    "pd_afr = pd.read_pickle(f\"./{tmp_data_path}/ma_fr_raw.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T01:43:41.898832Z",
     "start_time": "2021-09-14T01:43:41.068232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check df created ok: \n",
      "    gvkey  year       at     sale       m2b       lev       roa       ppe  \\\n",
      "0   1004  1997  529.584  589.328  1.495681  0.223368  0.043478  0.134271   \n",
      "\n",
      "   cash2asset  cash2sale  sale2asset        cr  d_sale  d_at  \n",
      "0    0.097633   0.087736    1.112813  4.141787     NaN   NaN  \n",
      "\n",
      " variable lists of ratio pd:  Index(['gvkey', 'year', 'at', 'sale', 'm2b', 'lev', 'roa', 'ppe', 'cash2asset',\n",
      "       'cash2sale', 'sale2asset', 'cr', 'd_sale', 'd_at'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ratio_pd_w_raw = create_var(pd_afr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change type to match SDC data\n",
    "\n",
    "in SDC data, we use string for every identifier (and eliminate the zeros in the front)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T01:43:53.816657Z",
     "start_time": "2021-09-14T01:43:53.194484Z"
    }
   },
   "outputs": [],
   "source": [
    "ratios_raw = ratio_pd_w_raw.copy()\n",
    "\n",
    "ratios_raw['gvkey'] = ratios_raw['gvkey'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T01:43:54.136502Z",
     "start_time": "2021-09-14T01:43:53.820096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving raw financial variable tables from 1997 to 2020; table size:  (277952, 14)\n"
     ]
    }
   ],
   "source": [
    "print(f\"saving raw financial variable tables from {s_year} to {e_year}; table size: \", ratio_pd_w_raw.shape)\n",
    "ratios_raw.to_pickle(f'{tmp_data_path}/fv_raw_{s_year}_{e_year}.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check NAs\n",
    "\n",
    "1. since we have devide operation, there are supposed to have inf and -inf if devide by 0\n",
    "    - replace `inf` as `na`\n",
    "\n",
    "2. only keep rows which na <  threshold\n",
    "3. replace na as mean value of the whole variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check how series is missing, \n",
    "\n",
    "- totally 288k rows has at least missing value\n",
    "- if we are ok to roughly drop 25% of the data, set thres = 5\n",
    "\n",
    "\n",
    "However, we don't want to drop many rows since we may have no positive samples for MA if do so.\n",
    "\n",
    "To decide what column to drop and how many row to drop, refer to [Appendix 2](./Appendix2_merge.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T22:13:06.847042Z",
     "start_time": "2021-09-14T22:13:06.844532Z"
    }
   },
   "outputs": [],
   "source": [
    "thres = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T22:13:07.698132Z",
     "start_time": "2021-09-14T22:13:07.694778Z"
    }
   },
   "outputs": [],
   "source": [
    "def rename_fins(df, acquiror):\n",
    "    '''\n",
    "    df contain targeting fin vars\n",
    "    acquiror: True or False\n",
    "    '''\n",
    "    key = 'A' if acquiror else 'T'\n",
    "    name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T22:13:08.253860Z",
     "start_time": "2021-09-14T22:13:08.236885Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_fv_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-88b41a7affef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_fv_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_fv_raw' is not defined"
     ]
    }
   ],
   "source": [
    "list(df_fv_raw.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T22:13:14.520087Z",
     "start_time": "2021-09-14T22:13:14.510796Z"
    }
   },
   "outputs": [],
   "source": [
    "# def helper fun\n",
    "def deal_na(df, na_thres):\n",
    "    '''\n",
    "    df: raw financial varibale table\n",
    "        - the first 2 columns are `gvkey` and `year`\n",
    "        - the rest are fianncial variables\n",
    "    \n",
    "    '''\n",
    "    n_features = len(df.columns) - 2\n",
    "    ratio_pd_w = df\n",
    "    # replace inf to na\n",
    "    ratio_pd_w.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    # count na of each row\n",
    "    ratio_pd_w['n_na'] = ratio_pd_w.isna().sum(axis=1) # each row has how many Nas\n",
    "     # only retain those Na < thres\n",
    "    ratio_pd_w = ratio_pd_w[ratio_pd_w['n_na'] <= na_thres].reset_index(drop=True)\n",
    "    \n",
    "    for colname in ratio_pd_w.columns[2:(2+n_features)]:\n",
    "        # remove outliers\n",
    "        ratio_pd_w[colname] = winsorize(ratio_pd_w[colname], limits=[0.01, 0.01], nan_policy='omit')\n",
    "        # impute na with mean\n",
    "        ratio_pd_w[colname].fillna(value=ratio_pd_w[colname].mean(skipna=True), inplace=True)\n",
    "    assert ratio_pd_w.isna().sum().sum() == 0\n",
    "    return ratio_pd_w\n",
    "\n",
    "\n",
    "def merge_fv_ma(df_fv_nona, df_ma):\n",
    "    '''\n",
    "    df_fv_nona: df_fv with no single missing value\n",
    "    df_ma: \n",
    "    \n",
    "    '''\n",
    "    assert df_fv_nona.isna().sum().sum() == 0\n",
    "    merge_a = df_ma.merge(df_fv_nona, how = 'inner', left_on=['AGVKEY', 'YEAR'], right_on = ['gvkey','year'])\n",
    "    merge_a.columns = list(merge_a.columns[0:len(merge_a.columns)-15]) + [x.upper()+'_A' for x in merge_a.columns[-15:]]\n",
    "    \n",
    "    merge_t =  merge_a.merge(df_fv_nona, how = 'inner', left_on=['TGVKEY', 'YEAR'], right_on = ['gvkey','year'])\n",
    "    merge_t.columns = list(merge_t.columns[0:len(merge_t.columns)-15]) + [x.upper()+'_T' for x in merge_t.columns[-15:]]\n",
    "\n",
    "    #print(\"num of obs for original MA table: \", df_ma.shape[0], '\\n')\n",
    "    #print('num of obs in merged table:', merge_t.shape[0], '\\n')\n",
    "    \n",
    "    return merge_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T22:13:19.410186Z",
     "start_time": "2021-09-14T22:13:19.129273Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ma = pd.read_pickle(pjoin(tmp_data_path , f'master1_{s_year}_{e_year}.pickle'))\n",
    "df_fv_raw = pd.read_pickle(f'{tmp_data_path}/fv_raw_{s_year}_{e_year}.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T22:13:21.169368Z",
     "start_time": "2021-09-14T22:13:20.120790Z"
    }
   },
   "outputs": [],
   "source": [
    "df_fv_nona = deal_na(df_fv_raw, thres)\n",
    "merged_fv_ma = merge_fv_ma(df_fv_nona, df_ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T22:14:03.070681Z",
     "start_time": "2021-09-14T22:14:02.859667Z"
    }
   },
   "outputs": [],
   "source": [
    "df_fv_nona.to_pickle(f'{tmp_data_path}/fv_nona_{s_year}_{e_year}.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T01:47:31.031201Z",
     "start_time": "2021-09-14T01:47:30.986900Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_fv_ma.drop(['GVKEY_A', 'GVKEY_T', 'YEAR_A', 'YEAR_T'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T01:47:32.825665Z",
     "start_time": "2021-09-14T01:47:32.820679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ACU', 'ASIC2', 'ABL', 'ANL', 'APUBC', 'AUP', 'AUPSIC', 'AUPBL',\n",
       "       'AUPNAMES', 'AUPPUB', 'BLOCK', 'CREEP', 'DA', 'DE', 'STATC', 'SYNOP',\n",
       "       'VAL', 'PCTACQ', 'PSOUGHTOWN', 'PSOUGHT', 'PHDA', 'PCTOWN', 'PSOUGHTT',\n",
       "       'PRIVATIZATION', 'DEAL_NO', 'TCU', 'TSIC2', 'TBL', 'TNL', 'TPUBC',\n",
       "       'TUP', 'TUPSIC', 'TUPBL', 'TUPNAMES', 'TUPPUB', 'AGVKEY', 'TGVKEY',\n",
       "       'GVKEY_OVERALL', 'YEAR', 'SIC_A', 'SIC_T', 'AT_A', 'SALE_A', 'M2B_A',\n",
       "       'LEV_A', 'ROA_A', 'PPE_A', 'CASH2ASSET_A', 'CASH2SALE_A',\n",
       "       'SALE2ASSET_A', 'CR_A', 'D_SALE_A', 'D_AT_A', 'N_NA_A', 'AT_T',\n",
       "       'SALE_T', 'M2B_T', 'LEV_T', 'ROA_T', 'PPE_T', 'CASH2ASSET_T',\n",
       "       'CASH2SALE_T', 'SALE2ASSET_T', 'CR_T', 'D_SALE_T', 'D_AT_T', 'N_NA_T'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_fv_ma.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T01:47:35.248123Z",
     "start_time": "2021-09-14T01:47:35.106459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df contains ma and fin var from 1997 to 2020, save to pickle, shape =  (7045, 67)\n"
     ]
    }
   ],
   "source": [
    "print(f'df contains ma and fin var from {s_year} to {e_year}, save to pickle, shape = ', merged_fv_ma.shape)\n",
    "merged_fv_ma.to_pickle(f'{tmp_data_path}/ma_fv_{s_year}_{e_year}.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
